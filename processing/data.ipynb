{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Data\n",
    "results = [\"./results/resultsContainerd.csv\", \"./results/resultsCRI-O.csv\", \"./results/resultsLXC.csv\", \"./results/resultsPodman.csv\"]\n",
    "# Engines\n",
    "engines = {'containerd': 'blue', 'CRI-O': 'red', 'lxc': 'green', 'podman': 'orange'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Core CPU Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average of 'CPU_Events/s' for each CSV file\n",
    "averages = [pd.read_csv(res)['CPU_Events/s'].mean() for res in results]\n",
    "\n",
    "# Create a DataFrame for the averages\n",
    "df_averages = pd.DataFrame({'Engine': list(engines.keys()), 'Average CPU_Events/s': averages})\n",
    "\n",
    "# Print the averages for each container engine\n",
    "for i, engine in enumerate(df_averages['Engine']):\n",
    "    print(f\"{engine}: {df_averages['Average CPU_Events/s'][i]}\")\n",
    "\n",
    "# Plot the averages in a bar graph with different colors for each container engine\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, engine in enumerate(df_averages['Engine']):\n",
    "    plt.bar(engine, df_averages['Average CPU_Events/s'][i], color=engines[engine])\n",
    "plt.title('Sysbench - Single Core CPU Performance (more is better)')\n",
    "plt.xlabel('Container Engine')\n",
    "plt.ylabel('Average CPU Events/s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average of 'Memory_Operations/s' for each CSV file\n",
    "averages = [pd.read_csv(res)['Memory_Operations/s'].mean() for res in results]\n",
    "\n",
    "# Create a DataFrame for the averages\n",
    "df_averages = pd.DataFrame({'Engine': list(engines.keys()), 'Memory_Operations/s': averages})\n",
    "\n",
    "# Print the averages for each container engine\n",
    "for i, engine in enumerate(df_averages['Engine']):\n",
    "    print(f\"{engine}: {df_averages['Average CPU_Events/s'][i]}\")\n",
    "\n",
    "\n",
    "# Plot the averages in a bar graph with different colors for each container engine\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, engine in enumerate(df_averages['Engine']):\n",
    "    plt.bar(engine, df_averages['Memory_Operations/s'][i], color=engines[engine])\n",
    "\n",
    "# Format y-axis labels to show full numbers\n",
    "formatter = FuncFormatter(lambda x, pos: '{:,.0f}'.format(x))\n",
    "plt.gca().yaxis.set_major_formatter(formatter)\n",
    "\n",
    "plt.title('Sysbench - RAM Performance (more is better)')\n",
    "plt.xlabel('Container Engine')\n",
    "plt.ylabel('Total operations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simultaneous Random read/write performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['rndrw_Reads/s', 'rndrw_Writes/s', 'rndrw_Fsyncs/s', 'rndrw_Read_MiB/s', 'rndrw_Written_MiB/s']\n",
    "\n",
    "# Calculate the average of each metric for each CSV file\n",
    "averages = []\n",
    "for res in results:\n",
    "    df = pd.read_csv(res)\n",
    "    averages.append({metric: df[metric].mean() for metric in metrics})\n",
    "\n",
    "# Create a DataFrame for the averages\n",
    "df_averages = pd.DataFrame(averages, index=list(engines.keys()))\n",
    "\n",
    "# Print the averages for each metric for each container engine\n",
    "for engine in df_averages.index:\n",
    "    print(f\"{engine}:\")\n",
    "    for metric in metrics:\n",
    "        print(f\"  {metric}: {df_averages.loc[engine, metric]}\")\n",
    "\n",
    "# Plot the averages in a bar graph with different colors for each container engine\n",
    "barWidth = 0.10\n",
    "r = np.arange(len(metrics))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i in range(len(df_averages)):\n",
    "    plt.bar(r + barWidth * i, df_averages.iloc[i], width=barWidth, color=engines[df_averages.index[i]], label=df_averages.index[i])\n",
    "\n",
    "plt.xticks([r + barWidth for r in range(len(metrics))], [metric.replace('rndrw_', '') for metric in metrics])\n",
    "plt.ylabel('Average Value')\n",
    "plt.title('FileIO - Simultaneous Random Read/Write Performance (more is better)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Random read/write performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['rndrd_Reads/s', 'rndwr_Writes/s','rndwr_Fsyncs/s','rndrd_Read_MiB/s','rndwr_Written_MiB/s']\n",
    "\n",
    "# Calculate the average of all metrics\n",
    "averages = []\n",
    "for res in results:\n",
    "    df = pd.read_csv(res)\n",
    "    averages.append({metric: df[metric].mean() for metric in metrics})\n",
    "\n",
    "# Create the dataframe\n",
    "df_averages = pd.DataFrame(averages, index=list(engines.keys()))\n",
    "\n",
    "# Print the averages for each metric for each container engine\n",
    "for engine in df_averages.index:\n",
    "    print(f\"{engine}:\")\n",
    "    for metric in metrics:\n",
    "        print(f\"  {metric}: {df_averages.loc[engine, metric]}\")\n",
    "\n",
    "# Create the bar graph\n",
    "barWidth = 0.10\n",
    "r = np.arange(len(metrics))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i in range(len(df_averages)):\n",
    "    plt.bar(r + barWidth * i, df_averages.iloc[i], width=barWidth, color=engines[df_averages.index[i]], label=df_averages.index[i])\n",
    "\n",
    "plt.xticks([r + barWidth for r in range(len(metrics))], [metric.replace('rndrd_', '').replace('rndwr_', '') for metric in metrics])\n",
    "plt.ylabel('Average value')\n",
    "plt.title('FileIO - Individual Random Read/Write Performance (more is better)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential read/write performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['seqrd_Reads/s', 'seqwr_Writes/s','seqwr_Fsyncs/s','seqrd_Read_MiB/s','seqwr_Written_MiB/s']\n",
    "\n",
    "# Calculate the average of all metrics\n",
    "averages = []\n",
    "for res in results:\n",
    "    df = pd.read_csv(res)\n",
    "    averages.append({metric: df[metric].mean() for metric in metrics})\n",
    "\n",
    "# Create the dataframe\n",
    "df_averages = pd.DataFrame(averages, index=list(engines.keys()))\n",
    "\n",
    "# Print the averages for each metric for each container engine\n",
    "for engine in df_averages.index:\n",
    "    print(f\"{engine}:\")\n",
    "    for metric in metrics:\n",
    "        print(f\"  {metric}: {df_averages.loc[engine, metric]}\")\n",
    "\n",
    "# Create the bar graph\n",
    "barWidth = 0.10\n",
    "r = np.arange(len(metrics))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i in range(len(df_averages)):\n",
    "    plt.bar(r + barWidth * i, df_averages.iloc[i], width=barWidth, color=engines[df_averages.index[i]], label=df_averages.index[i])\n",
    "\n",
    "plt.xticks([r + barWidth for r in range(len(metrics))], [metric.replace('seqrd_', '').replace('seqwr_', '') for metric in metrics])\n",
    "plt.ylabel('Average value')\n",
    "plt.title('FileIO - Individual Sequential Read/Write Performance (more is better)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential rewrite performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['seqrewr_Writes/s', 'seqrewr_Fsyncs/s' ,'seqrewr_Written_MiB/s']\n",
    "\n",
    "# Calculate the average of all metrics\n",
    "averages = []\n",
    "for res in results:\n",
    "    df = pd.read_csv(res)\n",
    "    averages.append({metric: df[metric].mean() for metric in metrics})\n",
    "\n",
    "# Create the dataframe\n",
    "df_averages = pd.DataFrame(averages, index=list(engines.keys()))\n",
    "\n",
    "# Print the averages for each metric for each container engine\n",
    "for engine in df_averages.index:\n",
    "    print(f\"{engine}:\")\n",
    "    for metric in metrics:\n",
    "        print(f\"  {metric}: {df_averages.loc[engine, metric]}\")\n",
    "\n",
    "# Create the bar graph\n",
    "barWidth = 0.10\n",
    "r = np.arange(len(metrics))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i in range(len(df_averages)):\n",
    "    plt.bar(r + barWidth * i, df_averages.iloc[i], width=barWidth, color=engines[df_averages.index[i]], label=df_averages.index[i])\n",
    "\n",
    "plt.xticks([r + barWidth for r in range(len(metrics))], [metric.replace('seqrewr_', '') for metric in metrics])\n",
    "plt.ylabel('Average value')\n",
    "plt.title('FileIO - Sequential Rewrite Performance (more is better)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Troughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = []\n",
    "\n",
    "# Calculate the average metrics\n",
    "for res in results:\n",
    "    df = pd.read_csv(res)\n",
    "    avg = df['Sender_troughput_Gb/s'].mean()\n",
    "    averages.append(avg)\n",
    "\n",
    "# Create a DataFrame for the averages\n",
    "df_averages = pd.DataFrame({'Engine': list(engines.keys()), 'Sender_troughput_Gb/s': averages})\n",
    "\n",
    "# Print the averages for each container engine\n",
    "for i, engine in enumerate(df_averages['Engine']):\n",
    "    print(f\"{engine}: {df_averages['Sender_troughput_Gb/s'][i]}\")\n",
    "\n",
    "\n",
    "# Plot the averages in a bar graph with different colors for each container engine\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(len(df_averages)):\n",
    "    plt.bar(df_averages['Engine'][i], df_averages['Sender_troughput_Gb/s'][i], color=engines[df_averages['Engine'][i]])\n",
    "plt.title('Iperf3 - Network Throughout (more is better)')\n",
    "plt.xlabel('Container Engine')\n",
    "plt.ylabel('Sender Troughtput Gb/s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['Minimaal', 'Gemiddelde', 'Maximaal']\n",
    "metric_mapping = {'Minimum_rtt': 'Minimaal', 'Average_rtt': 'Gemiddelde', 'Max_rtt': 'Maximaal'}\n",
    "engines = {'containerd': 'blue', 'CRI-O': 'red', 'lxc': 'green', 'podman': 'orange'}\n",
    "\n",
    "# Calculate the average of all metrics\n",
    "averages = []\n",
    "for res in results:\n",
    "    df = pd.read_csv(res)\n",
    "    averages.append({metric_mapping[metric]: df[metric].mean() for metric in metric_mapping})\n",
    "\n",
    "# Create the dataframe\n",
    "df_averages = pd.DataFrame(averages, index=list(engines.keys()))\n",
    "\n",
    "# Create the bar graph\n",
    "barWidth = 0.10\n",
    "r = np.arange(len(metrics))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i in range(len(df_averages)):\n",
    "    plt.bar(r + barWidth * i, df_averages.iloc[i], width=barWidth, color=engines[df_averages.index[i]], label=df_averages.index[i])\n",
    "\n",
    "plt.xticks([r + barWidth for r in range(len(metrics))], metrics)\n",
    "plt.ylabel('Latency (ms)')\n",
    "plt.title('Ping - Network Latency')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Print the averages for each metric for each container engine\n",
    "for engine in df_averages.index:\n",
    "    print(f\"{engine}:\")\n",
    "    for metric in metrics:\n",
    "        print(f\"  {metric}: {df_averages.loc[engine, metric]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
